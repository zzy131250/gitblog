# [从最小二乘法到梯度下降法（二）](https://github.com/zzy131250/gitblog/issues/21)

> 搬运自老博客，发表时间：2017-07-28

# 前言
[上一篇](https://github.com/zzy131250/gitblog/issues/20)我们介绍了最小二乘法，这是一种数学优化方法，常用于拟合回归。它的基本思想就是通过令参数的偏导数为0，计算残差平方和的最小值。但是这种方法有一定的局限性，就是不适合使用计算机进行计算，因为计算机不会解方程。
那么，有没有方便计算机进行计算的方法呢？答案当然是有的。计算机虽然不会解方程，但是它可以通过自己强大的计算能力，把最终答案一步一步试出来。这就是梯度下降法。

# 线性回归的例子

# 扩展到多重回归

# 随机梯度下降（SGD）

# 小批量梯度下降（MBGD）
上述两种梯度下降方法各有优势，而小批量梯度下降则将两者结合起来。顾名思义，该方法将样本分成多个批次，每个批次都有多个样本数据。在一次梯度函数 ∇F 的计算过程中，使用一批样本数据。跟BGD相比，MBGD计算梯度函数时样本量较少，效率高；跟SGD相比，MBGD使用小批量计算梯度，减小了梯度方向的误差，使得收敛速度更快。