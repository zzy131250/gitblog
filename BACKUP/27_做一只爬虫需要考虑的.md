# [做一只爬虫需要考虑的](https://github.com/zzy131250/gitblog/issues/27)

> 搬运自老博客，发表时间：2019-04-10

# 前言
整理一下做一只可靠的爬虫需要考虑的因素。
一次典型的爬取过程包括下载一个 URL 返回的页面，解析页面中的目标数据，将数据存储起来。那么，可以从网络、解析、存储三个方面来讨论分析。另外，爬虫还需要应对服务端的反爬虫策略。

# 网络
爬虫需要网络访问，网络下载速度越快，那么爬取效率会越高。当然，一般情况下，由于网站的反爬虫策略，爬虫对于网络的要求并不是很高，带宽不需要很大。因为，通常情况下反爬虫策略不允许短时间内的大量访问。
当然，对于客户端而言，最佳实践当然是使用单独的线程或进程进行异步的网络访问，因为 IO 操作相对于 CPU 来说相当耗时。

# 解析
网页的解析，就是从网页中提取需要的数据。主要的解析方式包括正则、Xpath、CSS 选择器等。对于爬虫来说，解析出需要的数据即可，根据不同的网页，可以挑选不同的方式。

# 存储
数据存储主要可分为文件和数据库，如果爬虫爬取的数据量不是很大，那么可以使用文件进行简单存储。而如果数据量达到一定规模，则优先考虑数据库。
数据库又分为关系型数据库，如 MySQL，和非关系型数据库，如 MongoDB。如何选择，则主要看使用场景，两者的对比可参考：[MongoDB and MySQL Compared](https://www.mongodb.com/zh-cn/compare/mongodb-mysql)。

# 反爬虫策略应对
## UA识别
对于通过 User-Agent 识别爬虫的策略，可以伪造 UA，并使用 UA 池，随机切换。另外可以伪装成浏览器爬虫，使用特定的 UA 爬取数据。

## 验证码
对于图片验证码，可以考虑使用 OCR 识别；对于滑块之类的验证手段，可以考虑 Selenium 模拟滑动。验证码是比较难以破解的反爬虫手段，目前也没有完美的方式。

## 频率限制
对于服务端的访问频率限制，可以随机 sleep 一段时间再爬取。

## 动态网页
对于动态网页，可以使用两种方式。
一是直接找到 Ajax 请求的 URL，进行爬取；二是通过 Selenium + 模拟浏览器，首先渲染出页面，再进行爬取。

## IP封锁
对于 IP 封锁，可使用 IP 代理池，随机切换 IP 爬取数据。

## Cookie验证
对于需要登录验证的网站，可以先使用网页登录，然后拿到 Cookie，进行爬取。或者使用 Selenium + 模拟浏览器直接登录，然后爬取数据。

---

> 好像挺多搬运的都是空贴？

working in progress